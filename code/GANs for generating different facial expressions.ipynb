{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from torch.backends import cudnn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True),\n",
    "            nn.LeakyReLU(0.01, inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, conv_dim=64, c_dim=5, repeat_num=6):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3+c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False), nn.InstanceNorm2d(conv_dim, affine=True), nn.LeakyReLU(0.01, inplace=True))\n",
    "\n",
    "        curr_dim = conv_dim\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False), nn.InstanceNorm2d(curr_dim*2, affine=True), nn.LeakyReLU(0.01, inplace=True))\n",
    "        curr_dim = curr_dim * 2\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1, bias=False), nn.InstanceNorm2d(curr_dim*2, affine=True), nn.LeakyReLU(0.01, inplace=True))\n",
    "        curr_dim = curr_dim * 2\n",
    "\n",
    "        layers = []\n",
    "        for i in range(repeat_num):\n",
    "            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n",
    "        self.main_res = nn.Sequential(*layers)\n",
    "\n",
    "        self.dconv3 = nn.Sequential(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False), nn.InstanceNorm2d(curr_dim//2, affine=True), nn.LeakyReLU(0.01, inplace=True))\n",
    "        curr_dim = curr_dim // 2\n",
    "        self.dconv2 = nn.Sequential(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=4, stride=2, padding=1, bias=False), nn.InstanceNorm2d(curr_dim//2, affine=True), nn.LeakyReLU(0.01, inplace=True))\n",
    "        curr_dim = curr_dim // 2\n",
    "\n",
    "        self.dconv1 = nn.Sequential(nn.Conv2d(curr_dim, 3, kernel_size=7, stride=1, padding=3, bias=False), nn.Tanh())\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        c = c.unsqueeze(2).unsqueeze(3)\n",
    "        c = c.expand(c.size(0), c.size(1), x.size(2), x.size(3))\n",
    "        xc = torch.cat([x, c], dim=1)\n",
    "\n",
    "        h1 = self.conv1(xc)\n",
    "        h2 = self.conv2(h1)\n",
    "        h3 = self.conv3(h2)\n",
    "        h4 = self.main_res(h3) + h3\n",
    "        h5 = self.dconv3(h4) + h2\n",
    "        h6 = self.dconv2(h5) + h1\n",
    "\n",
    "        return self.dconv1(h6) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size=128, conv_dim=64, c_dim=5, repeat_num=6):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.repeat_num = repeat_num\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1))\n",
    "        layers.append(nn.LeakyReLU(0.01, inplace=True))\n",
    "\n",
    "        curr_dim = conv_dim\n",
    "        for i in range(1, repeat_num):\n",
    "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=4, stride=2, padding=1))\n",
    "            layers.append(nn.LeakyReLU(0.01, inplace=True))\n",
    "            curr_dim = curr_dim * 2\n",
    "\n",
    "        k_size = int(image_size / np.power(2, repeat_num))\n",
    "        self.main = nn.Sequential(*layers)\n",
    "        self.conv1 = nn.Conv2d(curr_dim, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(curr_dim, c_dim, kernel_size=k_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        out_feats = []\n",
    "        for i in range(0, self.repeat_num):\n",
    "            h = nn.Sequential(*list(self.main.children())[i*2:(i+1)*2])(h)\n",
    "            if i < 4:\n",
    "                out_feats.append(h.squeeze())\n",
    "        out_real = self.conv1(h)\n",
    "        out_aux = self.conv2(h)\n",
    "        return out_real.squeeze(), out_aux.squeeze(), out_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "\n",
    "    def __init__(self, fer2013_loader, config):\n",
    "        self.fer2013_loader = fer2013_loader\n",
    "\n",
    "        self.c_dim = config.c_dim\n",
    "        self.c2_dim = config.c2_dim\n",
    "        self.image_size = config.image_size\n",
    "        self.g_conv_dim = config.g_conv_dim\n",
    "        self.d_conv_dim = config.d_conv_dim\n",
    "        self.g_repeat_num = config.g_repeat_num\n",
    "        self.d_repeat_num = config.d_repeat_num\n",
    "        self.d_train_repeat = config.d_train_repeat\n",
    "\n",
    "        self.lambda_cls = config.lambda_cls\n",
    "        self.lambda_rec = config.lambda_rec\n",
    "        self.lambda_gp = config.lambda_gp\n",
    "        self.lambda_feat_rec = config.lambda_feat_rec\n",
    "        self.g_lr = config.g_lr\n",
    "        self.d_lr = config.d_lr\n",
    "        self.beta1 = config.beta1\n",
    "        self.beta2 = config.beta2\n",
    "\n",
    "        self.dataset = config.dataset\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.num_epochs_decay = config.num_epochs_decay\n",
    "        self.num_iters = config.num_iters\n",
    "        self.num_iters_decay = config.num_iters_decay\n",
    "        self.batch_size = config.batch_size\n",
    "        self.use_tensorboard = config.use_tensorboard\n",
    "        self.pretrained_model = config.pretrained_model\n",
    "\n",
    "        self.test_model = config.test_model\n",
    "\n",
    "        self.sample_path = config.sample_path\n",
    "        self.model_save_path = config.model_save_path\n",
    "        self.result_path = config.result_path\n",
    "\n",
    "        self.sample_step = config.sample_step\n",
    "        self.model_save_step = config.model_save_step\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "        if self.pretrained_model:\n",
    "            self.load_pretrained_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.G = Generator(self.g_conv_dim, self.c_dim, self.g_repeat_num)\n",
    "        self.D = Discriminator(self.image_size, self.d_conv_dim, self.c_dim, self.d_repeat_num) \n",
    "\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), self.g_lr, [self.beta1, self.beta2])\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), self.d_lr, [self.beta1, self.beta2])\n",
    "\n",
    "        self.print_network(self.G, 'G')\n",
    "        self.print_network(self.D, 'D')\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "    def print_network(self, model, name):\n",
    "        num_params = 0\n",
    "        for p in model.parameters():\n",
    "            num_params += p.numel()\n",
    "        print(name)\n",
    "        print(model)\n",
    "        print(\"The number of parameters: {}\".format(num_params))\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        self.G.load_state_dict(torch.load(os.path.join(\n",
    "            self.model_save_path, '{}_G.pth'.format(self.pretrained_model))))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(\n",
    "            self.model_save_path, '{}_D.pth'.format(self.pretrained_model))))\n",
    "        print('loaded trained models')\n",
    "\n",
    "    def update_lr(self, g_lr, d_lr):\n",
    "        for param_group in self.g_optimizer.param_groups:\n",
    "            param_group['lr'] = g_lr\n",
    "        for param_group in self.d_optimizer.param_groups:\n",
    "            param_group['lr'] = d_lr\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.g_optimizer.zero_grad()\n",
    "        self.d_optimizer.zero_grad()\n",
    "\n",
    "    def to_var(self, x, volatile=False):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        return Variable(x, volatile=volatile)\n",
    "\n",
    "    def denorm(self, x):\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp_(0, 1)\n",
    "\n",
    "    def threshold(self, x):\n",
    "        x = x.clone()\n",
    "        x[x >= 0.5] = 1\n",
    "        x[x < 0.5] = 0\n",
    "        return x\n",
    "\n",
    "    def compute_accuracy(self, x, y, dataset):\n",
    "        _, predicted = torch.max(x, dim=1)\n",
    "        correct = (predicted == y).float()\n",
    "        accuracy = torch.mean(correct) * 100.0\n",
    "        return accuracy\n",
    "\n",
    "    def one_hot(self, labels, dim):\n",
    "        batch_size = labels.size(0)\n",
    "        out = torch.zeros(batch_size, dim)\n",
    "        out[np.arange(batch_size), labels.long()] = 1\n",
    "        return out\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        self.data_loader = self.fer2013_loader\n",
    "        iters_per_epoch = len(self.data_loader)\n",
    "\n",
    "        fixed_x = []\n",
    "        real_c = []\n",
    "        for i, (images, labels) in enumerate(self.data_loader):\n",
    "            fixed_x.append(images)\n",
    "            real_c.append(labels)\n",
    "            if i == 3:\n",
    "                break\n",
    "\n",
    "        fixed_x = torch.cat(fixed_x, dim=0)\n",
    "        fixed_x = self.to_var(fixed_x, volatile=True)\n",
    "        real_c = torch.cat(real_c, dim=0)\n",
    "\n",
    "        fixed_c_list = []\n",
    "        for i in range(self.c_dim):\n",
    "            fixed_c = self.one_hot(torch.ones(fixed_x.size(0)) * i, self.c_dim)\n",
    "            fixed_c_list.append(self.to_var(fixed_c, volatile=True))\n",
    "\n",
    "        g_lr = self.g_lr\n",
    "        d_lr = self.d_lr\n",
    "        if self.pretrained_model:\n",
    "            start = int(self.pretrained_model.split('_')[0])\n",
    "        else:\n",
    "            start = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for e in range(start, self.num_epochs):\n",
    "            print(\"LEN: \" + str(len(self.data_loader)))\n",
    "            for i, (real_x, real_label) in enumerate(self.data_loader):\n",
    "                \n",
    "                rand_idx = torch.randperm(real_label.size(0))\n",
    "                fake_label = real_label[rand_idx]\n",
    "\n",
    "                real_c = self.one_hot(real_label, self.c_dim)\n",
    "                fake_c = self.one_hot(fake_label, self.c_dim)\n",
    "\n",
    "                real_x = self.to_var(real_x)\n",
    "                real_c = self.to_var(real_c) \n",
    "                fake_c = self.to_var(fake_c)\n",
    "                real_label = self.to_var(real_label)  \n",
    "                fake_label = self.to_var(fake_label)\n",
    "                \n",
    "                #train discriminator\n",
    "\n",
    "                out_src, out_cls, out_feats_real = self.D(real_x)\n",
    "                d_loss_real = - torch.mean(out_src)\n",
    "\n",
    "                d_loss_cls = F.cross_entropy(out_cls, real_label)\n",
    "\n",
    "                fake_x = self.G(real_x, fake_c)\n",
    "                fake_x = Variable(fake_x.data)\n",
    "                out_src, out_cls, out_feats_fake = self.D(fake_x)\n",
    "                d_loss_fake = torch.mean(out_src)\n",
    "\n",
    "                d_loss = d_loss_real + d_loss_fake + self.lambda_cls * d_loss_cls\n",
    "                self.reset_grad()\n",
    "                d_loss.backward(retain_graph=True)\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                alpha = torch.rand(real_x.size(0), 1, 1, 1).cuda().expand_as(real_x)\n",
    "                interpolated = Variable(alpha * real_x.data + (1 - alpha) * fake_x.data, requires_grad=True)\n",
    "                out, out_cls, out_feats = self.D(interpolated)\n",
    "\n",
    "                grad = torch.autograd.grad(outputs=out,\n",
    "                                           inputs=interpolated,\n",
    "                                           grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                                           retain_graph=True,\n",
    "                                           create_graph=True,\n",
    "                                           only_inputs=True)[0]\n",
    "\n",
    "                grad = grad.view(grad.size(0), -1)\n",
    "                grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "                d_loss_gp = torch.mean((grad_l2norm - 1)**2)\n",
    "\n",
    "                d_loss = self.lambda_gp * d_loss_gp\n",
    "                self.reset_grad()\n",
    "                d_loss.backward(retain_graph=True)\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # train generator\n",
    "                if (i+1) % self.d_train_repeat == 0:\n",
    "\n",
    "                    fake_x = self.G(real_x, fake_c)\n",
    "                    rec_x = self.G(fake_x, real_c)\n",
    "\n",
    "                    out_src, out_cls, out_feats_fake = self.D(fake_x)\n",
    "                    g_loss_fake = - torch.mean(out_src)\n",
    "\n",
    "                    g_loss_cls = F.cross_entropy(out_cls, fake_label)\n",
    "\n",
    "                    out_src, out_cls, out_feats_rec = self.D(rec_x)\n",
    "                    g_loss_rec = torch.mean(torch.abs(real_x - rec_x))\n",
    "\n",
    "                    g_loss = g_loss_fake + self.lambda_cls * g_loss_cls + self.lambda_rec * g_loss_rec\n",
    "                    self.reset_grad()\n",
    "                    g_loss.backward(retain_graph=True)\n",
    "                    self.g_optimizer.step()\n",
    "\n",
    "                if (i+1) % self.sample_step == 0:\n",
    "                    fake_image_list = [fixed_x]\n",
    "                    for fixed_c in fixed_c_list:\n",
    "                        fake_image_list.append(self.G(fixed_x, fixed_c))\n",
    "                    fake_images = torch.cat(fake_image_list, dim=3)\n",
    "                    save_image(self.denorm(fake_images.data),\n",
    "                        os.path.join(self.sample_path, '{}_{}_fake.png'.format(e+1, i+1)),nrow=1, padding=0)\n",
    "                    print('Images saved into {}..!'.format(self.sample_path))\n",
    "\n",
    "                if (i+1) % self.model_save_step == 0:\n",
    "                    torch.save(self.G.state_dict(),\n",
    "                        os.path.join(self.model_save_path, '{}_{}_G.pth'.format(e+1, i+1)))\n",
    "                    torch.save(self.D.state_dict(),\n",
    "                        os.path.join(self.model_save_path, '{}_{}_D.pth'.format(e+1, i+1)))\n",
    "\n",
    "            if (e+1) > (self.num_epochs - self.num_epochs_decay):\n",
    "                g_lr -= (self.g_lr / float(self.num_epochs_decay))\n",
    "                d_lr -= (self.d_lr / float(self.num_epochs_decay))\n",
    "                self.update_lr(g_lr, d_lr)\n",
    "                print ('Decay learning rate to g_lr: {}, d_lr: {}.'.format(g_lr, d_lr))\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        G_path = os.path.join(self.model_save_path, '{}_G.pth'.format(self.test_model))\n",
    "        self.G.load_state_dict(torch.load(G_path))\n",
    "        self.G.eval()\n",
    "\n",
    "        data_loader = self.fer2013_loader\n",
    "        \n",
    "\n",
    "        label_name_list = ['Angry', 'Happy', 'Sad', 'Surprise']\n",
    "        for label_name in label_name_list:\n",
    "            label_path = os.path.join(self.result_path, 'fer2013', 'test', label_name)\n",
    "            if not os.path.exists(label_path):\n",
    "                os.makedirs(label_path)\n",
    "\n",
    "        for i, (real_x, org_c) in enumerate(data_loader):\n",
    "            real_x = self.to_var(real_x, volatile=True)\n",
    "\n",
    "            target_c_list = []\n",
    "            for j in range(self.c_dim):\n",
    "                target_c = self.one_hot(torch.ones(real_x.size(0)) * j, self.c_dim)\n",
    "                target_c_list.append(self.to_var(target_c, volatile=True))\n",
    "\n",
    "            fake_image_list = [real_x]\n",
    "            for target_c in target_c_list:\n",
    "                fake_x = self.G(real_x, target_c)\n",
    "                fake_image_list.append(fake_x)\n",
    "\n",
    "                tc = np.where(target_c.data.cpu().numpy() == 1)[1]\n",
    "                for k in range(real_x.size(0)):\n",
    "                    save_path = os.path.join(self.result_path, 'fer2013', 'test', label_name_list[tc[k]], '{}_fake.png'.format(i*real_x.size(0)+k))\n",
    "                    save_image(self.denorm(fake_x.data[k,:,:,:]), save_path, nrow=1, padding=0)\n",
    "            fake_images = torch.cat(fake_image_list, dim=3)\n",
    "            save_path = os.path.join(self.result_path, '{}_fake.png'.format(i+1))\n",
    "            save_image(self.denorm(fake_images.data), save_path, nrow=1, padding=0)\n",
    "            print('Images saved into \"{}\"..!'.format(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(image_path, metadata_path, crop_size, image_size, batch_size, dataset='fer2013', mode='train'):\n",
    "    if mode == 'train':\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    dataset = ImageFolder(image_path, transform)\n",
    "\n",
    "    shuffle = False\n",
    "    if mode == 'train':\n",
    "        shuffle = True\n",
    "\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in ('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if not os.path.exists(config.log_path):\n",
    "        os.makedirs(config.log_path)\n",
    "    if not os.path.exists(config.model_save_path):\n",
    "        os.makedirs(config.model_save_path)\n",
    "    if not os.path.exists(config.sample_path):\n",
    "        os.makedirs(config.sample_path)\n",
    "    if not os.path.exists(config.result_path):\n",
    "        os.makedirs(config.result_path)\n",
    "\n",
    "    fer2013_loader = None\n",
    "    \n",
    "    fer2013_loader = get_loader(config.fer2013_image_path, None, config.fer2013_crop_size,\n",
    "                                 config.image_size, config.batch_size, 'fer2013', config.mode)\n",
    "    solver = Solver(fer2013_loader, config)\n",
    "\n",
    "    if config.mode == 'train':\n",
    "        solver.train()\n",
    "    elif config.mode == 'test':\n",
    "        solver.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, batch_size, beta1, beta2, c2_dim, c_dim, d_conv_dim, d_lr, d_repeat_num, d_train_repeat, dataset, fer2013_crop_size, \n",
    "                 fer2013_image_path, g_conv_dim, g_lr, g_repeat_num, image_size, lambda_cls, lambda_feat_rec, lambda_gp, lambda_rec, log_path, \n",
    "                 log_step, mode, model_save_path, model_save_step, num_epochs, num_epochs_decay, num_iters, num_iters_decay, num_workers, \n",
    "                 pretrained_model, result_path, sample_path, sample_step, test_model):\n",
    "        self.batch_size = batch_size\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.c2_dim = c2_dim\n",
    "        self.c_dim = c_dim\n",
    "        self.d_conv_dim = d_conv_dim\n",
    "        self.d_lr = d_lr\n",
    "        self.d_repeat_num = d_repeat_num\n",
    "        self.d_train_repeat = d_train_repeat\n",
    "        self.dataset = dataset\n",
    "        self.fer2013_crop_size = fer2013_crop_size\n",
    "        self.fer2013_image_path = fer2013_image_path\n",
    "        self.g_conv_dim = g_conv_dim\n",
    "        self.g_lr = g_lr\n",
    "        self.g_repeat_num = g_repeat_num\n",
    "        self.image_size = image_size\n",
    "        self.lambda_cls = lambda_cls\n",
    "        self.lambda_feat_rec = lambda_feat_rec\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.lambda_rec = lambda_rec\n",
    "        self.log_path = log_path\n",
    "        self.log_step = log_step\n",
    "        self.mode = mode\n",
    "        self.model_save_path = model_save_path\n",
    "        self.model_save_step = model_save_step\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_epochs_decay = num_epochs_decay\n",
    "        self.num_iters = num_iters\n",
    "        self.num_iters_decay = num_iters_decay\n",
    "        self.num_workers = num_workers\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.result_path = result_path\n",
    "        self.sample_path = sample_path\n",
    "        self.sample_step = sample_step\n",
    "        self.test_model = test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "config_train = Config(batch_size=8, beta1=0.5, beta2=0.999, c2_dim=8, c_dim=2, d_conv_dim=64, d_lr=0.0001, d_repeat_num=6, d_train_repeat=5, \n",
    "               dataset='fer2013', fer2013_crop_size=48, fer2013_image_path='./fer2013/train', g_conv_dim=64, g_lr=0.0001, g_repeat_num=6,\n",
    "               image_size=64, lambda_cls=1, lambda_feat_rec=10, lambda_gp=10, lambda_rec=10, log_path='./stargan/logs',\n",
    "               log_step=50, mode='train', model_save_path='./stargan/models', model_save_step=1000, num_epochs=400, \n",
    "               num_epochs_decay=100, num_iters=2000, num_iters_decay=100000, num_workers=8, pretrained_model='300_1000', \n",
    "               result_path='./stargan/results', sample_path='./stargan/samples', \n",
    "               sample_step=1000, test_model='20_1000')\n",
    "#main(config_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "config_test = Config(batch_size=1, beta1=0.5, beta2=0.999, c2_dim=8, c_dim=2,\n",
    "                     d_conv_dim=64, d_lr=0.0001, d_repeat_num=6, d_train_repeat=5, dataset='fer2013', fer2013_crop_size=48,\n",
    "                     fer2013_image_path='./fer2013/test', \n",
    "                     g_conv_dim=64, g_lr=0.0001, g_repeat_num=6, image_size=64, lambda_cls=1, lambda_feat_rec=10, lambda_gp=10, \n",
    "                     lambda_rec=10, log_path='./stargan/logs', log_step=10, \n",
    "                     mode='test', model_save_path='./stargan/models', model_save_step=4, \n",
    "                     num_epochs=20, num_epochs_decay=10, num_iters=200000, num_iters_decay=100000, num_workers=8, pretrained_model=None, \n",
    "                     result_path='./stargan/results', \n",
    "                     sample_path='./stargan/samples', sample_step=500, test_model='400_1000')\n",
    "#main(config_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
